# Áü•ËØÜÁÇπ
- RDDÁöÑÁõ∏ÂÖ≥Ê¶ÇÂøµÔºå‰∫ÜËß£HDFSÁöÑÂàÜÂ∏ÉÂºèÂ≠òÂÇ®ÔºåmapreduceÁöÑÊÄùÊÉ≥ÔºåÁ®ãÂ∫èÁöÑÂπ∂Ë°åÂåñËøõË°å
- SparkÂàÜ‰∏∫ËΩ¨Êç¢Êìç‰ΩúÂíåÂä®‰ΩúÔºåDAGÁöÑËµÑÊ∫êËÆ°ÁÆóÂõæÂè™ÊúâÂú®actionÁöÑÊó∂ÂÄôÊâç‰ºöËß¶ÂèëËøêÁÆóÔºåÂè™Êúâ‰∏≠Èó¥ÁªìÊûúË¢´cache„ÄÅpersisÁöÑÊó∂ÂÄôÊâç‰ºöÊöÇÂ≠òÔºåÂê¶Âàô‰ºöÈáçÂ§çËÆ°ÁÆó
- broadcastÂíåaccumulatorÂÖ±‰∫´ÂèòÈáèÔºåÂ±ÄÈÉ®ÁöÑglobal‰πüÊòØlocalÁöÑ
- sparkÁöÑDFÊìç‰Ωú
- sparkÁöÑgraphÊìç‰Ωú
- sparkÁöÑÊú∫Âô®Â≠¶‰π†Â∫ì
- streamÊìç‰Ωú
- HbaseÂíåHive

### Âπ∂Ë°åÁ®ãÂ∫èÈóÆÈ¢òÔºö 
- Ê≠ªÈîÅÈóÆÈ¢òÔºö‰ø°Âè∑Èáè+‰∫íÊñ•ÈîÅ  
- restricted - Á∫¶Êùü   deterministic - Á°ÆÂÆöÁöÑ
### RDD  
Spark Ê†∏ÂøÉÁöÑÊ¶ÇÂøµÊòØ Resilient Distributed Dataset (RDD)Ôºö‰∏Ä‰∏™ÂèØÂπ∂Ë°åÊìç‰ΩúÁöÑÊúâÂÆπÈîôÊú∫Âà∂ÁöÑÊï∞ÊçÆÈõÜÂêà„ÄÇÊúâ 2 ÁßçÊñπÂºèÂàõÂª∫ RDDsÔºöÁ¨¨‰∏ÄÁßçÊòØÂú®‰Ω†ÁöÑÈ©±Âä®Á®ãÂ∫è‰∏≠Âπ∂Ë°åÂåñ‰∏Ä‰∏™Â∑≤ÁªèÂ≠òÂú®ÁöÑÈõÜÂêàÔºõÂè¶Â§ñ‰∏ÄÁßçÊòØÂºïÁî®‰∏Ä‰∏™Â§ñÈÉ®Â≠òÂÇ®Á≥ªÁªüÁöÑÊï∞ÊçÆÈõÜÔºå‰æãÂ¶ÇÂÖ±‰∫´ÁöÑÊñá‰ª∂Á≥ªÁªüÔºåHDFSÔºåHBaseÊàñÂÖ∂‰ªñ Hadoop Êï∞ÊçÆÊ†ºÂºèÁöÑÊï∞ÊçÆÊ∫ê„ÄÇÔºàtextfileÔºâ    
partitionÊòØspark rddËÆ°ÁÆóÁöÑÊúÄÂ∞èÂçïÂÖÉ„ÄÇ  
Spark RDD‰∏ªË¶ÅÁî±Dependency„ÄÅPartition„ÄÅPartitionerÁªÑÊàê„ÄÇ  
    1. PartitionËÆ∞ÂΩï‰∫ÜÊï∞ÊçÆsplitÁöÑÈÄªËæëÔºå  
    2. DependencyËÆ∞ÂΩïÁöÑÊòØtransformationÊìç‰ΩúËøáÁ®ã‰∏≠PartitionÁöÑÊºîÂåñÔºå  
    3. PartitionerÊòØshuffleËøáÁ®ã‰∏≠keyÈáçÂàÜÂå∫Êó∂ÁöÑÁ≠ñÁï•ÔºåÂç≥ËÆ°ÁÆókeyÂÜ≥ÂÆök-vÂ±û‰∫éÂì™‰∏™ÂàÜÂå∫  
#### Âπ∂Ë°åÂåñ  
Âπ∂Ë°åÈõÜÂêà (Parallelized collections) ÁöÑÂàõÂª∫ÊòØÈÄöËøáÂú®‰∏Ä‰∏™Â∑≤ÊúâÁöÑÈõÜÂêà(Scala Seq)‰∏äË∞ÉÁî® SparkContext ÁöÑ parallelize ÊñπÊ≥ïÂÆûÁé∞ÁöÑ„ÄÇÈõÜÂêà‰∏≠ÁöÑÂÖÉÁ¥†Ë¢´Â§çÂà∂Âà∞‰∏Ä‰∏™ÂèØÂπ∂Ë°åÊìç‰ΩúÁöÑÂàÜÂ∏ÉÂºèÊï∞ÊçÆÈõÜ‰∏≠„ÄÇ‰æãÂ¶ÇÔºåËøôÈáåÊºîÁ§∫‰∫ÜÂ¶Ç‰ΩïÂú®‰∏Ä‰∏™ÂåÖÂê´ 1 Âà∞ 5 ÁöÑÊï∞ÁªÑ‰∏≠ÂàõÂª∫Âπ∂Ë°åÈõÜÂêàÔºö
```python
val data = Array(1, 2, 3, 4, 5)
val distData = sc.parallelize(data)
```
### Map-Reduce  
- store: GFS-google distribute file system  
### Hadoop  
- open source of google GFS and MR  
- Master(task tracker+name node | 64MB chunk Â≠óÂÖ∏) + Slave(task tracker+data node Â≠òÂÇ®chunk,Â§çÂà∂‰∏â‰ªΩÔºåÂú®‰∏çÂêåÁöÑslaver node‰∏≠)  
- HDFS+Hadoop MR  
- ÂøÉË∑≥ 
- Map-> ÂàÜÈÖçÂà∞‰∏çÂêåÁöÑworker|Prase-hash : convert str into a number(means the index of woker) -> Reduce
- Áº∫ÁÇπÔºö 
> lost transaction features etc.  
> Êö¥Âäõ‰ª£ÊõøÁ¥¢Âºï  
- ÁªÑÊàê  
> master: **job tracker**    NameNode  
> worker(slaver):map-reduce+ DataNode  **task tracker**  

### Spark
- features:  
rich api;in-memory storage;**execution graph**;interactive shell  
- Structure and features  
Á∫øÊÄßËÆ°ÁÆóÊµÅÂõæÔºåËÆ°ÁÆóÂÆåÊØï‰ºö‰∏¢ÂºÉÁªìÊûúÔºåÂÜç‰ΩøÁî®‰ºöÊ†πÊçÆËÆ°ÁÆóÂõæ‰ªéÂ¶Ç‰Ωï‰∫ßÁîüÁöÑÂú∞ÊñπÂÜçËÆ°ÁÆó‰∏ÄÈÅç
- ËΩ¨Êç¢Êìç‰ΩúÔºö Transform:,map,filter,repartition,union,distinct
    - mapÁ≠âÔºåÊØè‰∏Ä‰∏™Êï∞ÊçÆÈõÜÂÖÉÁ¥†‰º†ÈÄíÁªô‰∏Ä‰∏™ÂáΩÊï∞Âπ∂‰∏îËøîÂõû‰∏Ä‰∏™Êñ∞ÁöÑ RDDÔºåÂπ∂‰∏ç‰ºöÁ´ãÂç≥ËøõË°åËÆ°ÁÆóÔºåÂπ∂‰∏îËΩ¨Êç¢ÁöÑ‰∏≠Èó¥ÁªìÊûúÈªòËÆ§‰∏ÄÊ¨°ÊÄß
- ActionÔºöreduce,count,first,takeSample
    - reduce ÊòØ‰∏Ä‰∏™Âä®‰ΩúÔºåÈõÜÂêàÊâÄÊúâÂÖÉÁ¥†Âπ∂ËøîÂõû
- still HDFS layer  
RDD store 1 copy not 3 like hdfs  
master separate RDDs  
data transpart via pipeline,to learner formed different rdds, no need to store intermediate results  
if one failed, just recompute in parallel and in different nodes from compute graph, not rollback.  
lines.cache()/persist(): ÊöÇÂ≠òÔºåËÆ°ÁÆóÂÆå‰∏ç‰ºöÁ´ãÈ©¨Ë¢´‰∏¢ÂºÉÔºå‰ªéËÄåÈÅøÂÖçËÆ°ÁÆóÂ§öÈÅç  
LRU ‰∏¢ÂºÉÊúÄ‰πÖÊú™‰ΩøÁî®ÁöÑÊóßÊï∞ÊçÆ .Âç≥‰ΩøÂéüÂßãÊï∞ÊçÆÂèò‰∫ÜÔºå‰πüÊ≤°ÊúâÂÖ≥Á≥ª  
python global varibale ‰ºöË¢´ÈÄÅÂà∞ÊØè‰∏Ä‰∏™executor,pythonÂáΩÊï∞‰πü‰ºöË¢´ÂèëÈÄÅÂà∞‰∏çÂêårdd‰∏ä


```python   
val lines = sc.textFile("data.txt")  
val lineLengths = lines.map(s => s.length)  
val totalLength = lineLengths.reduce((a, b) => a + b)
```
> Á¨¨‰∏ÄË°åÊòØÂÆö‰πâÊù•Ëá™‰∫éÂ§ñÈÉ®Êñá‰ª∂ÁöÑ RDD„ÄÇËøô‰∏™Êï∞ÊçÆÈõÜÂπ∂Ê≤°ÊúâÂä†ËΩΩÂà∞ÂÜÖÂ≠òÊàñÂÅöÂÖ∂‰ªñÁöÑÊìç‰ΩúÔºölines‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™ÊåáÂêëÊñá‰ª∂ÁöÑÊåáÈíà„ÄÇÁ¨¨‰∫åË°åÊòØÂÆö‰πâ lineLengthsÔºåÂÆÉÊòØ mapËΩ¨Êç¢(transformation)ÁöÑÁªìÊûú„ÄÇÂêåÊ†∑ÔºålineLengthsÁî±‰∫éÊáíÊÉ∞Ê®°Âºè‰πüÊ≤°ÊúâÁ´ãÂç≥ËÆ°ÁÆó„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÊâßË°å reduceÔºåÂÆÉÊòØ‰∏Ä‰∏™Âä®‰Ωú(action)„ÄÇÂú®Ëøô‰∏™Âú∞ÊñπÔºåSparkÊääËÆ°ÁÆóÂàÜÊàêÂ§ö‰∏™‰ªªÂä°(task)ÔºåÂπ∂‰∏îËÆ©ÂÆÉ‰ª¨ËøêË°åÂú®Â§ö‰∏™Êú∫Âô®‰∏ä„ÄÇÊØèÂè∞Êú∫Âô®ÈÉΩËøêË°åËá™Â∑±ÁöÑ map ÈÉ®ÂàÜÂíåÊú¨Âú∞reduce ÈÉ®ÂàÜ„ÄÇÁÑ∂Âêé‰ªÖ‰ªÖÂ∞ÜÁªìÊûúËøîÂõûÁªôÈ©±Âä®Á®ãÂ∫è„ÄÇ  



Internal:  
### PartitionÔºö

Êü•ÁúãJOBÔºöhttp://127.0.0.1:4040/jobs/job/?id=0  
ÊØè‰∏Ä‰∏™workerÔºàmachineÔºâÂèØ‰ª•ÂåÖÂê´Â§ö‰∏™partitionÔºåpartition‰∏ÄËà¨ÊòØÂ§ÑÁêÜÂô®Ê†∏ÂøÉÁöÑÊï∞Èáè   
1„ÄÅrepartitionÁ±ªÁöÑÊìç‰ΩúÔºöÊØîÂ¶Çrepartition„ÄÅrepartitionAndSortWithinPartitions„ÄÅcoalesceÁ≠â  
2„ÄÅbyKeyÁ±ªÁöÑÊìç‰ΩúÔºöÊØîÂ¶ÇreduceByKey„ÄÅgroupByKey„ÄÅsortByKey„ÄÅcountByKeyÁ≠â  
3„ÄÅjoinÁ±ªÁöÑÊìç‰ΩúÔºöÊØîÂ¶Çjoin„ÄÅcogroupÁ≠â  

SparkÊîØÊåÅÔºö  
Two kinds of partitioning available in Spark:  
- Hash partitioning  
- Range partitioning  

Êï∞ÊçÆË∞ÉÁî®hashCodeÂáΩÊï∞ÂàÜÈÖçÊï∞ÊçÆÔºö  
In general, hash partitioning allocates tuple (k, v) to partition p where 
p = k.hashCode() % numPartitions
Usually works well but be aware of bad inputs!  
‰æãÂ¶ÇÔºö
We see that it hashed all numbers x such that x mod 8 = 1 to partition #1    

def glom(): RDD[Array[T]]

ËØ•ÂáΩÊï∞ÊòØÂ∞ÜRDD‰∏≠ÊØè‰∏Ä‰∏™ÂàÜÂå∫‰∏≠Á±ªÂûã‰∏∫TÁöÑÂÖÉÁ¥†ËΩ¨Êç¢ÊàêArray[T]ÔºåËøôÊ†∑ÊØè‰∏Ä‰∏™ÂàÜÂå∫Â∞±Âè™Êúâ‰∏Ä‰∏™Êï∞ÁªÑÂÖÉÁ¥†   
when the default partition function (hashing) doesn‚Äôt work well -„Äã a custom partition function  
Specify the partition function in transformations like reduceByKey, groupByKey


Map:ËøôÈáåÊúâ‰∏Ä‰∏™ÊÄßËÉΩÈóÆÈ¢òÔºåmapÂõ†‰∏∫ÂèØËÉΩ‰ºöÊîπÂèòkeyÔºåËÄåpartitionÊòØÊåâÁÖßkeyÊù•ÂàÜÁöÑÔºåÊâÄ‰ª•Â∞±ÈúÄË¶ÅÊî∂ÂõûÁÑ∂ÂêéÂÜçhash->partitionÂàÜ‰∏ãÂéªÊâßË°åÔºõËÄåmapvaluesÂè™ÂèòvalueÔºåÊâÄ‰ª•‰∏çÁî®ÂÜçpartition  
- map(function)   
mapÊòØÂØπRDD‰∏≠ÁöÑÊØè‰∏™ÂÖÉÁ¥†ÈÉΩÊâßË°å‰∏Ä‰∏™ÊåáÂÆöÁöÑÂáΩÊï∞Êù•‰∫ßÁîü‰∏Ä‰∏™Êñ∞ÁöÑRDD„ÄÇ‰ªª‰ΩïÂéüRDD‰∏≠ÁöÑÂÖÉÁ¥†Âú®Êñ∞RDD‰∏≠ÈÉΩÊúâ‰∏îÂè™Êúâ‰∏Ä‰∏™ÂÖÉÁ¥†‰∏é‰πãÂØπÂ∫î„ÄÇ  
- mapPartitions(function)   
map()ÁöÑËæìÂÖ•ÂáΩÊï∞ÊòØÂ∫îÁî®‰∫éRDD‰∏≠ÊØè‰∏™ÂÖÉÁ¥†ÔºåËÄåmapPartitions()ÁöÑËæìÂÖ•ÂáΩÊï∞ÊòØÂ∫îÁî®‰∫éÊØè‰∏™ÂàÜÂå∫  
- mapValues(function)   
ÂéüRDD‰∏≠ÁöÑKey‰øùÊåÅ‰∏çÂèòÔºå‰∏éÊñ∞ÁöÑValue‰∏ÄËµ∑ÁªÑÊàêÊñ∞ÁöÑRDD‰∏≠ÁöÑÂÖÉÁ¥†„ÄÇÂõ†Ê≠§ÔºåËØ•ÂáΩÊï∞Âè™ÈÄÇÁî®‰∫éÂÖÉÁ¥†‰∏∫KVÂØπÁöÑRDD  
- flatMap(function)   
‰∏émapÁ±ª‰ººÔºåÂå∫Âà´ÊòØÂéüRDD‰∏≠ÁöÑÂÖÉÁ¥†ÁªèmapÂ§ÑÁêÜÂêéÂè™ËÉΩÁîüÊàê‰∏Ä‰∏™ÂÖÉÁ¥†ÔºåËÄåÂéüRDD‰∏≠ÁöÑÂÖÉÁ¥†ÁªèflatmapÂ§ÑÁêÜÂêéÂèØÁîüÊàêÂ§ö‰∏™ÂÖÉÁ¥†Ôºå***‰ºöÊ∂àÂéª‰∏ÄÁ∫ßËøõË°åÂêàÂπ∂ÔºåÂèòÊàê‰∏Ä‰∏™list***  

- ÂàÜÂå∫Êìç‰Ωú  
Ôºà1ÔºâmapPartitions
def mapPartitions[U](f: (Iterator[T]) => Iterator[U], preservesPartitioning: Boolean = false)(implicit arg0: ClassTag[U]): RDD[U]
ËØ•ÂáΩÊï∞ÂíåmapÂáΩÊï∞Á±ª‰ººÔºåÂè™‰∏çËøáÊò†Â∞ÑÂáΩÊï∞ÁöÑÂèÇÊï∞Áî±RDD‰∏≠ÁöÑÊØè‰∏Ä‰∏™ÂÖÉÁ¥†ÂèòÊàê‰∫ÜRDD‰∏≠ÊØè‰∏Ä‰∏™ÂàÜÂå∫ÁöÑËø≠‰ª£Âô®„ÄÇÂ¶ÇÊûúÂú®Êò†Â∞ÑÁöÑËøáÁ®ã‰∏≠ÈúÄË¶ÅÈ¢ëÁπÅÂàõÂª∫È¢ùÂ§ñÁöÑÂØπË±°ÔºàÂ¶ÇÊï∞ÊçÆÂ∫ìËøûÊé•ÂØπË±°ÔºâÔºå‰ΩøÁî®mapPartitionsË¶ÅÊØîmapÈ´òÊïàÁöÑÂ§ö„ÄÇ
ÊØîÂ¶ÇÔºåÂ∞ÜRDD‰∏≠ÁöÑÊâÄÊúâÊï∞ÊçÆÈÄöËøáJDBCËøûÊé•ÂÜôÂÖ•Êï∞ÊçÆÂ∫ìÔºåÂ¶ÇÊûú‰ΩøÁî®mapÂáΩÊï∞ÔºåÂèØËÉΩË¶Å‰∏∫ÊØè‰∏Ä‰∏™ÂÖÉÁ¥†ÈÉΩÂàõÂª∫‰∏Ä‰∏™connectionÔºåËøôÊ†∑ÂºÄÈîÄÂæàÂ§ßÔºåÂ¶ÇÊûú‰ΩøÁî®mapPartitionsÔºåÈÇ£‰πàÂè™ÈúÄË¶ÅÈíàÂØπÊØè‰∏Ä‰∏™ÂàÜÂå∫Âª∫Á´ã‰∏Ä‰∏™connection„ÄÇ

‰æùËµñÈóÆÈ¢òÔºö
wide dependenciesÔºö‰∏çÂú®‰∏Ä‰∏™partition‰∏äÈù¢ÔºåÈúÄË¶ÅshuffleÔºü
narrowÔºõÔºõ

shuffle: ÊèêÂâçÂÅöÂ•ΩÂπ≥Ë°°ÔºåË¥πËµÑÊ∫ê
repartition: same tumple column is in the same partition


JobÔºöÁúüÊ≠£ÁöÑËøêË°åËµ∑Êù•Âä®‰Ωú
ÂæàÂ§ö‰∏™stageÁªÑÊàê‰∏Ä‰∏™job,ÊØè‰∏Ä‰∏™threadÂèØ‰ª•ËøêË°å‰∏Ä‰∏™jobËææÂà∞Âπ∂Ë°åÁöÑÊïàÊûú

‰∏Ä‰∏™RDD Âè™ËÉΩÊòØ‰∏Ä‰∏™key-value pairÔºåÂèØ‰ª•Ë¢´ÂàÜÊàêÂ§ö‰∏™partitionÔºå‰∏ÄËà¨Êù•ËØ¥ÊØè‰∏™worker(‰∏ÄËà¨ÊòØcore ÁöÑÊï∞ÈáèÔºåÂç≥JVM)ËøêË°å‰∏§‰∏™Ôºå‰ΩÜÊòØspark‰ºöÊääÊÖ¢ÁöÑpartition‰º†Âà∞Âø´ÁöÑworker‰∏äËøêË°å

## Êï∞ÊçÆÂÄæÊñú
- ‰∏∫skewÁöÑkeyÂ¢ûÂä†ÈöèÊú∫Ââç/ÂêéÁºÄ  
ÂéüÁêÜ
‰∏∫Êï∞ÊçÆÈáèÁâπÂà´Â§ßÁöÑKeyÂ¢ûÂä†ÈöèÊú∫Ââç/ÂêéÁºÄÔºå‰ΩøÂæóÂéüÊù•KeyÁõ∏ÂêåÁöÑÊï∞ÊçÆÂèò‰∏∫Key‰∏çÁõ∏ÂêåÁöÑÊï∞ÊçÆÔºå‰ªéËÄå‰ΩøÂÄæÊñúÁöÑÊï∞ÊçÆÈõÜÂàÜÊï£Âà∞‰∏çÂêåÁöÑTask‰∏≠ÔºåÂΩªÂ∫ïËß£ÂÜ≥Êï∞ÊçÆÂÄæÊñúÈóÆÈ¢ò„ÄÇJoinÂè¶‰∏ÄÂàôÁöÑÊï∞ÊçÆ‰∏≠Ôºå‰∏éÂÄæÊñúKeyÂØπÂ∫îÁöÑÈÉ®ÂàÜÊï∞ÊçÆÔºå‰∏éÈöèÊú∫ÂâçÁºÄÈõÜ‰ΩúÁ¨õÂç°Â∞î‰πòÁßØÔºå‰ªéËÄå‰øùËØÅÊó†ËÆ∫Êï∞ÊçÆÂÄæÊñú‰æßÂÄæÊñúKeyÂ¶Ç‰ΩïÂä†ÂâçÁºÄÔºåÈÉΩËÉΩ‰∏é‰πãÊ≠£Â∏∏Join„ÄÇ
- Â∞ÜReduce side JoinËΩ¨Âèò‰∏∫Map side Join  
- Ëá™ÂÆö‰πâPartitioner  
ÂéüÁêÜ
- ‰ΩøÁî®Ëá™ÂÆö‰πâÁöÑPartitionerÔºàÈªòËÆ§‰∏∫HashPartitionerÔºâÔºåÂ∞ÜÂéüÊú¨Ë¢´ÂàÜÈÖçÂà∞Âêå‰∏Ä‰∏™TaskÁöÑ‰∏çÂêåKeyÂàÜÈÖçÂà∞‰∏çÂêåTask„ÄÇ  
- ‰ΩøÁî®PartitionerÂøÖÈ°ªÊª°Ë∂≥‰∏§‰∏™ÂâçÊèêÔºå1„ÄÅRDDÊòØk-vÂΩ¢ÂºèÔºåÂ¶ÇRDD[(K, V)]Ôºå2„ÄÅÊúâshuffleÊìç‰Ωú„ÄÇÂ∏∏ËßÅÁöÑËß¶ÂèëshuffleÁöÑÊìç‰ΩúÊúâÔºö 
    1.combineByKey(groupByKey, reduceByKey , aggregateByKey) 
    2. sortByKey 
    3. join(leftOuterJoin, rightOuterJoin, fullOuterJoin) 
    4. cogroup 
    5. repartition(coalesce(shuffle=true)) 
    6. groupWith 
    7. repartitionAndSortWithinPartitions


## Classical Divide-and-Conquer:  

Âè™ÊúâÂÖ®ÈÉ®ÁöÑÁªìÊûúÔºåÊ≤°Êúâ‰∏≠Èó¥ÁöÑÊàñËÄÖprefix resultÔºàÂâçp‰∏™ÂéüÂÖÉÁ¥†ÁöÑÂíåÔºâ  
ËÆ°ÁÆóprefixÁöÑparallelÔºöÈíàÂØπÂ∫èÂàóËÆ°ÁÆóÔºåÂ¶Ç‰ΩïËøõË°åÂπ∂Ë°åÂåñ
Algorithm:
- Compute sum for each partition ÊØè‰∏™partitionÁöÑÂ∞èsum
- Compute the prefix sums of the ùëù 
- Compute prefix sums in each partition

x = [1, 4, 3, 5, 6, 7, 0, 1]  
sum = [5, 8, 13, 1] mapPartitions
prefix_sum = [1, 5, 8, 13, 19, 26, 26, 27]  mapPartitionsWithIndex  

### ÂÖ±‰∫´ÂèòÈáè
sparkÂ∞ÜÂáΩÊï∞ÂíåÂèòÈáèÁöÑÁã¨Á´ãÂâØÊú¨‰º†ÈÄíÁªôworkersÔºåÊõ¥Êñ∞‰∏ç‰ºöËøîÂõûÁªôÈ©±Âä®Á®ãÂ∫èÔºåÊòØÁöÑË∑®‰ªªÂä°ËØªÂÜôÈÄüÂ∫¶ÂæàÊÖ¢
- ÂπøÊí≠ÂèòÈáèÔºàbroadcast variableÔºâ
SparkContext.broadcast(v)ÊñπÊ≥ï‰ªé‰∏Ä‰∏™ÂàùÂßãÂèòÈáèv‰∏≠ÂàõÂª∫„ÄÇÂπøÊí≠ÂèòÈáèÊòØvÁöÑ‰∏Ä‰∏™ÂåÖË£ÖÂèòÈáèÔºåÂÆÉÁöÑÂÄºÂèØ‰ª•ÈÄöËøávalueÊñπÊ≥ïËÆøÈóÆ
- Á¥ØÂä†Âô®ÔºàaccumulatorÔºâ
ÈÄöËøáË∞ÉÁî®SparkContext.accumulator(v)ÊñπÊ≥ï‰ªé‰∏Ä‰∏™ÂàùÂßãÂèòÈáèv‰∏≠ÂàõÂª∫„ÄÇËøêË°åÂú®ÈõÜÁæ§‰∏äÁöÑ‰ªªÂä°ÂèØ‰ª•ÈÄöËøáaddÊñπÊ≥ïÊàñËÄÖ‰ΩøÁî®+=Êìç‰ΩúÊù•ÁªôÂÆÉÂä†ÂÄº„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨Êó†Ê≥ïËØªÂèñËøô‰∏™ÂÄº„ÄÇÂè™ÊúâÈ©±Âä®Á®ãÂ∫èÂèØ‰ª•‰ΩøÁî®valueÊñπÊ≥ïÊù•ËØªÂèñÁ¥ØÂä†Âô®ÁöÑÂÄº

# set

setÊúâ‰∏§ÁßçÁ±ªÂûãÔºåsetÂíåfrozenset„ÄÇ

setÊòØÂèØÂèòÁöÑÔºåÊúâaddÔºàÔºâÔºåremoveÔºàÔºâÁ≠âÊñπÊ≥ï„ÄÇÊó¢ÁÑ∂ÊòØÂèØÂèòÁöÑÔºåÊâÄ‰ª•ÂÆÉ‰∏çÂ≠òÂú®ÂìàÂ∏åÂÄº„ÄÇ

frozensetÊòØÂÜªÁªìÁöÑÈõÜÂêàÔºåÂÆÉÊòØ‰∏çÂèØÂèòÁöÑÔºåÂ≠òÂú®ÂìàÂ∏åÂÄºÔºåÂ•ΩÂ§ÑÊòØÂÆÉÂèØ‰ª•‰Ωú‰∏∫Â≠óÂÖ∏ÁöÑkeyÔºå‰πüÂèØ‰ª•‰Ωú‰∏∫ÂÖ∂ÂÆÉÈõÜÂêàÁöÑÂÖÉÁ¥†„ÄÇÁº∫ÁÇπÊòØ‰∏ÄÊó¶ÂàõÂª∫‰æø‰∏çËÉΩÊõ¥ÊîπÔºåÊ≤°ÊúâaddÔºåremoveÊñπÊ≥ï„ÄÇ


[img](http://dongguo.me/images/personal/engineering/spark/spark-components.png)


### Ê≠£Á°ÆÂú∞‰ΩøÁî®ÂπøÊí≠ÂèòÈáè(broadcast variables)
- ÂπøÊí≠ÂèòÈáèÂÖÅËÆ∏Á®ãÂ∫èÂëòÂ∞Ü‰∏Ä‰∏™Âè™ËØªÁöÑÂèòÈáèÁºìÂ≠òÂú®ÊØèÂè∞Êú∫Âô®‰∏äÔºåËÄå‰∏çÁî®Âú®‰ªªÂä°‰πãÈó¥‰º†ÈÄíÂèòÈáè„ÄÇÂπøÊí≠ÂèòÈáèÂèØË¢´Áî®‰∫éÊúâÊïàÂú∞ÁªôÊØè‰∏™ËäÇÁÇπ‰∏Ä‰∏™Â§ßËæìÂÖ•Êï∞ÊçÆÈõÜÁöÑÂâØÊú¨„ÄÇ
‰∏Ä‰∏™ExecutorÂè™ÈúÄË¶ÅÂú®Á¨¨‰∏Ä‰∏™TaskÂêØÂä®Êó∂ÔºåËé∑Âæó‰∏Ä‰ªΩBroadcastÊï∞ÊçÆÔºå‰πãÂêéÁöÑTaskÈÉΩ‰ªéÊú¨ËäÇÁÇπÁöÑBlockManager‰∏≠Ëé∑ÂèñÁõ∏ÂÖ≥Êï∞ÊçÆ„ÄÇ

- Â¶ÇÊûúÊàë‰ª¨Êúâ‰∏Ä‰ªΩconstÊï∞ÊçÆÔºåÈúÄË¶ÅÂú®executors‰∏äÁî®Âà∞Ôºå‰∏Ä‰∏™ÂÖ∏ÂûãÁöÑ‰æãÂ≠êÊòØDriver‰ªéÊï∞ÊçÆÂ∫ì‰∏≠load‰∫Ü‰∏Ä‰ªΩÊï∞ÊçÆdbDataÔºåÂú®ÂæàÂ§öRDDÊìç‰Ωú‰∏≠ÈÉΩÂºïÁî®‰∫ÜdbDataÔºåËøôÊ†∑ÁöÑËØùÔºåÊØèÊ¨°RDDÊìç‰ΩúÔºådriver nodeÈÉΩÈúÄË¶ÅÂ∞ÜdbDataÂàÜÂèëÂà∞ÂêÑ‰∏™executors node‰∏ÄÈÅçÔºàÂàÜ‰∫´1‰∏≠Â∑≤Áªè‰ªãÁªç‰∫ÜËÉåÊôØÔºâÔºåËøôÈùûÂ∏∏ÁöÑ‰ΩéÊïàÔºåÁâπÂà´ÊòØdbDataÊØîËæÉÂ§ß‰∏îRDDÊìç‰ΩúÊ¨°Êï∞ËæÉÂ§öÊó∂„ÄÇSparkÁöÑÂπøÊí≠ÂèòÈáè‰ΩøÂæóDriverÂèØ‰ª•ÊèêÂâçÂè™ÁªôÂêÑ‰∏™executors node‰º†‰∏ÄÈÅçÔºàsparkÂÜÖÈÉ®ÂÖ∑‰ΩìÁöÑÂÆûÁé∞ÂèØËÉΩÊòØdriver‰º†ÁªôÊüêÂá†‰∏™executorsÔºåËøôÂá†‰∏™executorsÂÜç‰º†ÁªôÂÖ∂‰ΩôexecutorsÔºâ„ÄÇ‰ΩøÁî®ÂπøÊí≠ÂèòÈáèÊúâ‰∏Ä‰∏™ÊàëÁäØËøáÁöÑÈîôËØØÂ¶Ç‰∏ãÔºö

``` javascript
 val brDbData = sparkContext.broadcast(dbData) //broadcast dbDataA, and name it as brDbData
 val dbDataB = brDbData.value //no longer broadcast variable
 oneRDD.map(x=>{dbDataB.getOrElse(key, -1); ‚Ä¶})
 ```
Á¨¨‰∏ÄË°åÂ∞ÜdbDataÂ∑≤ÁªèÂπøÊí≠Âá∫Âéª‰∏îÂëΩÂêç‰∏∫brDbDataÔºå‰∏ÄÂÆöË¶ÅÂú®RDDÊìç‰Ωú‰∏≠Áõ¥Êé•‰ΩøÁî®ËØ•ÂπøÊí≠ÂèòÈáèÔºåÂ¶ÇÊûúÊèêÂâçÊèêÂèñÂá∫ÂÄºÔºåÁ¨¨‰∏âË°åÁöÑRDDÊìç‰ΩúËøòÈúÄË¶ÅÂ∞ÜdbData‰º†ÈÄÅ‰∏ÄÈÅç„ÄÇÊ≠£Á°ÆÁöÑ‰ª£Á†ÅÂ¶Ç‰∏ã

 ``` javascript
 val brDbData = sparkContext.broadcast(dbData) //broadcast dbDataA, and name it as brDbData
 oneRDD.map(x=>{brDbData.value.getOrElse(key, -1); ‚Ä¶})
 ```
SparkÊú¨Ë∫´ÊîØÊåÅÂÅöbatchÁöÑËÆ°ÁÆóÔºåÊØîÂ¶ÇÊØèÂ§©Êú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑËÆ≠ÁªÉÔºåÂêÑÁßçÊï∞ÊçÆÁöÑÂ§ÑÁêÜÔºõ
Spark StreamingÂèØ‰ª•Áî®Êù•ÂÅörealtimeËÆ°ÁÆóÂíåÊï∞ÊçÆÂ§ÑÁêÜÔºåSpark StreamingÁöÑAPIÂíåSparkÁöÑÊØîËæÉÁ±ª‰ººÔºåÂÖ∂ÂÆûËÉåÂêéÁöÑÂÆûÁé∞‰πüÊòØÊää‰∏ÄÊÆµÊÆµÁöÑrealtimeÊï∞ÊçÆÁî®batchÁöÑÊñπÂºèÂéªÂ§ÑÁêÜÔºõ
MLlibÂÆûÁé∞‰∫ÜÂ∏∏Áî®ÁöÑÊú∫Âô®Â≠¶‰π†ÂíåÊé®ËçêÁÆóÊ≥ïÔºåÂèØ‰ª•Áõ¥Êé•Áî®ÊàñËÄÖ‰Ωú‰∏∫baselineÔºõ
Spark SQL‰ΩøÂæóÂèØ‰ª•ÈÄöËøáSQLÊù•ÂØπHiveË°®ÔºåJsonÊñá‰ª∂Á≠âÊï∞ÊçÆÊ∫êËøõË°åÊü•ËØ¢ÔºåÊü•ËØ¢‰ºöË¢´ËΩ¨Âèò‰∏∫‰∏Ä‰∏™Spark jobÔºõ

- ‰∏ÄËà¨ÂèØ‰ª•ËÆæÁΩÆtaskÁöÑÊï∞ÈáèÊòØcoreÁöÑ2-3ÂÄçÔºåËÆ©CPU‰∏çÁ©∫Èó≤
- 
### stream  
- streamingContext.start()  
Start receiving data and processing it using 
- streamingContext.awaitTermination()  
Wait for the processing to be stopped 
- streamingContext.stop()  
(manually or due to any error) using The processing can be manually stopped using streamingContext.stop().  
. To stop only the StreamingContextÔºö ssc.stop(False)
- DStreams can be created   
    - from input data streams 
    - by applying high-level operations on other DStreams.
#### Streaming MG analysis


### Hbase table ÂàóÂ≠òÂÇ®
È´òÈöèÊú∫ËØªÂÜô‰∏çÊîØÊåÅjoinÔºå
An open-source version of Google BigTable  
HBase is a distributed column-oriented data store built on top of HDFS  
HBase is an Apache open source project whose goal is to provide storage for Hadoop Distributed Computing   
Data is logically organized into tables, rows and columns 
- Each row has a Key
- Each record is divided into Column Families
- Each column family consists of one or more Columns
- HBase schema consists of several Tables  
    Each table consists of a set of Column Families  
    Columns are not part of the schema 
#### Hive: data warehousing application in Hadoop Á±ª‰ººsql  
Query language is HQL, variant of SQL  
Tables stored on HDFS as flat files  
Developed by Facebook, now open source  
Hive looks similar to an SQL database
Support Joins

### ÂáΩÊï∞Ôºö
glomÔºö  
Â∞ÜRDD‰∏≠ÊØè‰∏Ä‰∏™ÂàÜÂå∫‰∏≠Á±ªÂûã‰∏∫TÁöÑÂÖÉÁ¥†ËΩ¨Êç¢ÊàêArray[T]ÔºåËøôÊ†∑ÊØè‰∏Ä‰∏™ÂàÜÂå∫Â∞±Âè™Êúâ‰∏Ä‰∏™Êï∞ÁªÑÂÖÉÁ¥†„ÄÇ


Platform as a Service: Âπ≥Âè∞Âç≥ÊúçÂä°, ÊòØÈù¢ÂêëËΩØ‰ª∂ÂºÄÂèëËÄÖÁöÑÊúçÂä°, ‰∫ëËÆ°ÁÆóÂπ≥Âè∞Êèê‰æõÁ°¨‰ª∂,
SaaS: ËΩØ‰ª∂Âç≥ÊúçÂä°, ÊòØÈù¢ÂêëËΩØ‰ª∂Ê∂àË¥πËÄÖÁöÑ

# Â∏∏Áî®‰ª£Á†ÅÂíåÈóÆÈ¢ò


```python 
# Âú®Notebook‰∏≠ËøêË°åspark
from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession
sc = SparkContext()
spark = SparkSession(sc)

# ÂàÜÂå∫‰∏§ÁßçÊñπÂºè  ÂèØ‰ª•Áî® partitionBy(4,lambda x:x%4)
rdd = sc.parallelize([('a', 1), ('a', 2), ('b', 1), ('b', 3), ('c',1), ('ef',5)])
rdd1 = rdd.repartition(4)
rdd1.glom().collect()

# reduceByKey Áõ∏ÂêåÁöÑkeyÁõ∏Âä†ÔºåFalseÊòØÈôçÂ∫è
 pairs.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).sortBy(lambda x:x[1], False).zipWithIndex().map(lambda x:(x[1],x[0]))
 
 #graph Êìç‰Ωú
 rule12 = g.find('(a)-[]->(b)').filter('a.id == "h"').select('b.name')
 
 # DFÊìç‰Ωú  .toDF()
TotalPrice = dfDetail.select('*',(dfDetail.UnitPrice*dfDetail.OrderQty*(1-dfDetail.UnitPriceDiscount)).alias('netprice'))\
            .groupBy('SalesOrderID').sum('netprice')\
                .withColumnRenamed('sum(netprice)','TotalPrice')

```