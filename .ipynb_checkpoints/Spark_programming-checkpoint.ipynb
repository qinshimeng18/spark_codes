{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# partitioner shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 会消掉一级进行合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [('a', 1), ('a', 2), ('b', 1), ('b', 3), ('c', 1), ('ef', 5)]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('a', 2), ('b', 1), ('b', 3), ('c',1), ('ef',5)])\n",
    "rdd1 = rdd.repartition(4)\n",
    "rdd1.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.parallelize([8,96,240,400,401,500,650,800]).flatMap(lambda x: [(x, x)]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(8, 8), (96, 96)],\n",
       " [(240, 240), (400, 400)],\n",
       " [(401, 401), (500, 500)],\n",
       " [(650, 650), (800, 800)]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([8,96,240,400,401,500,650,800]).map(lambda x: (x, x))\n",
    "rdd.partitionBy(4,lambda x:(x-1)/(800/4)).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(8, 8), (96, 96), (240, 240), (400, 400), (500, 500), (800, 800)],\n",
       " [(401, 401)],\n",
       " [(650, 650)],\n",
       " []]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.partitionBy(4).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [(8, 8),\n",
       "  (96, 96),\n",
       "  (240, 240),\n",
       "  (400, 400),\n",
       "  (401, 401),\n",
       "  (500, 500),\n",
       "  (650, 650),\n",
       "  (800, 800)]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.repartition(4).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([34,67,32,21,5,24,45,36,89])\n",
    "index = 6\n",
    "while True:\n",
    "    x = rdd.first() #Changed after first time\n",
    "    left = rdd.filter(lambda z:z<x)\n",
    "    right = rdd.filter(lambda z:z>x)\n",
    "    mid = left.count()\n",
    "    if mid == index:\n",
    "        print '==',x\n",
    "        break\n",
    "    if index < mid:\n",
    "        rdd = left\n",
    "    else:\n",
    "        rdd = right\n",
    "        index = index - mid -1\n",
    "        rdd.cache()\n",
    "    print left.collect(),right.collect(),rdd.collect(),index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the adjective-noun pairs with frequency and find the median pair.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[536] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numPartitions = 10\n",
    "lines = sc.textFile('adj_noun_pairs.txt', numPartitions)\n",
    "pairs = lines.map(lambda l: tuple(l.split())).filter(lambda p: len(p)==2)\n",
    "pairs.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[612] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_freq = pairs.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).sortBy(lambda x:x[1], False).zipWithIndex()\n",
    "pairs_freq.cache()\n",
    "\n",
    "\n",
    "# .zipWithIndex().map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'indic', u'tamil'), 1)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_i = pairs.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).sortBy(lambda x:x[1], False).zipWithIndex().map(lambda x:(x[1],x[0]))\n",
    "middle = pairs_i.count()/2\n",
    "pairs_i.lookup(middle)\n",
    "\n",
    "# .zipWithIndex().map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((u'external', u'link'), 8136), 0),\n",
       " (((u'19th', u'century'), 2869), 1),\n",
       " (((u'20th', u'century'), 2816), 2),\n",
       " (((u'same', u'time'), 2744), 3),\n",
       " (((u'first', u'time'), 2632), 4)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_freq.map(lambda x:x).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ((u'external', u'link'), 8136)),\n",
       " (1, ((u'19th', u'century'), 2869)),\n",
       " (2, ((u'20th', u'century'), 2816)),\n",
       " (3, ((u'same', u'time'), 2744)),\n",
       " (4, ((u'first', u'time'), 2632))]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_freq.map(lambda x:(x[1],x[0])).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((u'external', u'link'), 8136), 0),\n",
       " (((u'19th', u'century'), 2869), 1),\n",
       " (((u'20th', u'century'), 2816), 2),\n",
       " (((u'same', u'time'), 2744), 3)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_freq.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'external', u'link'), 8136),\n",
       " ((u'19th', u'century'), 2869),\n",
       " ((u'20th', u'century'), 2816)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).sortBy(lambda x:x[1], False).take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业 2 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Customer.csv')\n",
    "df2 = pd.read_csv('SalesOrderDetail.csv')\n",
    "df3 = pd.read_csv('SalesOrderHeader.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>NameStyle</th>\n",
       "      <th>Title</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Suffix</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>SalesPerson</th>\n",
       "      <th>EmailAddress</th>\n",
       "      <th>Phone</th>\n",
       "      <th>PasswordHash</th>\n",
       "      <th>PasswordSalt</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>N.</td>\n",
       "      <td>Gee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Bike Store</td>\n",
       "      <td>adventure-works\\pamela0</td>\n",
       "      <td>orlando0@adventure-works.com</td>\n",
       "      <td>245-555-0173</td>\n",
       "      <td>L/Rlwxzp4w7RWmEgXX+/A7cXaePEPcp+KwQhl2fJL7w=</td>\n",
       "      <td>1KjXYs4=</td>\n",
       "      <td>3F5AE95E-B87D-4AED-95B4-C3797AFCB74F</td>\n",
       "      <td>2005-08-01 00:00:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  NameStyle Title FirstName MiddleName LastName Suffix  \\\n",
       "0           1          0   Mr.   Orlando         N.      Gee    NaN   \n",
       "\n",
       "    CompanyName              SalesPerson                  EmailAddress  \\\n",
       "0  A Bike Store  adventure-works\\pamela0  orlando0@adventure-works.com   \n",
       "\n",
       "          Phone                                  PasswordHash PasswordSalt  \\\n",
       "0  245-555-0173  L/Rlwxzp4w7RWmEgXX+/A7cXaePEPcp+KwQhl2fJL7w=     1KjXYs4=   \n",
       "\n",
       "                                rowguid             ModifiedDate  \n",
       "0  3F5AE95E-B87D-4AED-95B4-C3797AFCB74F  2005-08-01 00:00:00.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1.columns,df2.columns,df3.columns\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesOrderID</th>\n",
       "      <th>SalesOrderDetailID</th>\n",
       "      <th>OrderQty</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>UnitPriceDiscount</th>\n",
       "      <th>LineTotal</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71774</td>\n",
       "      <td>110562</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>356.898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356.898</td>\n",
       "      <td>E3A1994C-7A68-4CE8-96A3-77FDD3BBD730</td>\n",
       "      <td>2008-06-01 00:00:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalesOrderID  SalesOrderDetailID  OrderQty  ProductID  UnitPrice  \\\n",
       "0         71774              110562         1        836    356.898   \n",
       "\n",
       "   UnitPriceDiscount  LineTotal                               rowguid  \\\n",
       "0                0.0    356.898  E3A1994C-7A68-4CE8-96A3-77FDD3BBD730   \n",
       "\n",
       "              ModifiedDate  \n",
       "0  2008-06-01 00:00:00.000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesOrderID</th>\n",
       "      <th>RevisionNumber</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>DueDate</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>OnlineOrderFlag</th>\n",
       "      <th>SalesOrderNumber</th>\n",
       "      <th>PurchaseOrderNumber</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>BillToAddressID</th>\n",
       "      <th>ShipMethod</th>\n",
       "      <th>CreditCardApprovalCode</th>\n",
       "      <th>SubTotal</th>\n",
       "      <th>TaxAmt</th>\n",
       "      <th>Freight</th>\n",
       "      <th>TotalDue</th>\n",
       "      <th>Comment</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71774</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-06-01 00:00:00.000</td>\n",
       "      <td>2008-06-13 00:00:00.000</td>\n",
       "      <td>2008-06-08 00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SO71774</td>\n",
       "      <td>PO348186287</td>\n",
       "      <td>10-4020-000609</td>\n",
       "      <td>...</td>\n",
       "      <td>1092</td>\n",
       "      <td>CARGO TRANSPORT 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>880.3484</td>\n",
       "      <td>70.4279</td>\n",
       "      <td>22.0087</td>\n",
       "      <td>972.785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89E42CDC-8506-48A2-B89B-EB3E64E3554E</td>\n",
       "      <td>2008-06-08 00:00:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalesOrderID  RevisionNumber                OrderDate  \\\n",
       "0         71774               2  2008-06-01 00:00:00.000   \n",
       "\n",
       "                   DueDate                 ShipDate  Status  OnlineOrderFlag  \\\n",
       "0  2008-06-13 00:00:00.000  2008-06-08 00:00:00.000       5                0   \n",
       "\n",
       "  SalesOrderNumber PurchaseOrderNumber   AccountNumber  \\\n",
       "0          SO71774         PO348186287  10-4020-000609   \n",
       "\n",
       "            ...             BillToAddressID         ShipMethod  \\\n",
       "0           ...                        1092  CARGO TRANSPORT 5   \n",
       "\n",
       "   CreditCardApprovalCode  SubTotal   TaxAmt  Freight  TotalDue  Comment  \\\n",
       "0                     NaN  880.3484  70.4279  22.0087   972.785      NaN   \n",
       "\n",
       "                                rowguid             ModifiedDate  \n",
       "0  89E42CDC-8506-48A2-B89B-EB3E64E3554E  2008-06-08 00:00:00.000  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfCustom = spark.read.csv('Customer.csv', header=True, inferSchema=True)\n",
    "dfDetail   = spark.read.csv('SalesOrderDetail.csv', header=True, inferSchema=True)\n",
    "dfHeader   = spark.read.csv('SalesOrderHeader.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CustomerID=1, SalesOrderID=None), Row(CustomerID=2, SalesOrderID=None)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CustomID.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'inner', 'outer', 'full', 'fullouter', 'leftouter', 'left', 'rightouter', 'right', 'leftsemi', 'leftanti', 'cross'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TotalPrice = dfDetail.select('*',(dfDetail.UnitPrice*dfDetail.OrderQty*(1-dfDetail.UnitPriceDiscount)).alias('netprice'))\\\n",
    "            .groupBy('SalesOrderID').sum('netprice')\\\n",
    "                .withColumnRenamed('sum(netprice)','TotalPrice')#.collect()#.take(1)\n",
    "CustomID = dfCustom.join(dfHeader,'CustomerID','left').select('CustomerID','SalesOrderID')\n",
    "df = CustomID.join(TotalPrice,'SalesOrderID','left').groupBy('CustomerID').sum('TotalPrice').withColumnRenamed('sum(TotalPrice)','TotalPrice').na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CustomerID=516, count=1), Row(CustomerID=29942, count=1)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CustomID.join(TotalPrice,'SalesOrderID','left').groupBy('CustomerID').count().sort('count',ascending = False).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TotalPrice = dfDetail.select('*',(dfDetail.UnitPrice*dfDetail.OrderQty*(1-dfDetail.UnitPriceDiscount)).alias('netprice')).groupBy('SalesOrderID').sum('netprice').withColumnRenamed('sum(netprice)','TotalPrice')\n",
    "\n",
    "CustomID = dfCustom.join(dfHeader,'CustomerID','left').select('CustomerID','SalesOrderID')\n",
    "\n",
    "df = CustomID.join(TotalPrice,'SalesOrderID','left').groupBy('CustomerID').sum('TotalPrice').withColumnRenamed('sum(TotalPrice)','TotalPrice').na.fill(0)\n",
    "\n",
    "#Calculate the average spending for all customer.\n",
    "\n",
    "mean = df.groupBy().avg(\"TotalPrice\").take(1)[0][0]\n",
    "\n",
    "#Filter for the final answer.\n",
    "\n",
    "df = df.filter(df.TotalPrice > mean).sort(\"TotalPrice\",ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业3 RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[550] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numPartitions = 10\n",
    "lines = sc.textFile('adj_noun_pairs.txt', numPartitions)\n",
    "pairs = lines.map(lambda l: tuple(l.split())).filter(lambda p: len(p)==2)\n",
    "pairs.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'external', u'link'), 8136),\n",
       " ((u'19th', u'century'), 2869),\n",
       " ((u'20th', u'century'), 2816)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).sortBy(lambda x:x[1],False).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'indic', u'tamil'), 1)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPair = pairs.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).sortBy(lambda x:x[1], False).zipWithIndex().map(lambda x:(x[1],x[0]))\n",
    "\n",
    "CNT = TPair.count()/2\n",
    "\n",
    "TPair.lookup(CNT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e1 = g.edges.filter(\"relationship = 'follow'\")\n",
    "v1 = e1.groupBy('dst').count().select('dst')\n",
    "v2 = e1.groupBy('src').count().orderBy('count', ascending=False)\n",
    "v3 = v2.select('src').subtract(v1.select('dst'))\n",
    "v4 = v3.join(v2,'src').first()\n",
    "v.filter(v['id']==v4.src).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile('wasb://cluster@msbd.blob.core.windows.net/data/adj_noun_pairs.txt', numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = lines.map(lambda l: tuple(l.split())).filter(lambda p: len(p)==2)\n",
    "pairs.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(src=9, dst=4),\n",
       " Row(src=1, dst=2),\n",
       " Row(src=1, dst=3),\n",
       " Row(src=2, dst=1),\n",
       " Row(src=4, dst=1)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = sc.parallelize([(1,2),(1,3),(9,4),(2,1),(3,1),(4,1)]).toDF([\"src\",\"dst\"])\n",
    "r = sc.parallelize([(1,),(2,),  (9,),(4,)]).toDF(['src'])\n",
    "# r1 = e.join(r,'src').groupBy('dst').count()\n",
    "# r1.show()\n",
    "e.join(r,'src').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 1), (4, 1)], [(1, 2), (1, 3), (9, 4), (3, 1)], [], []]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([(1,2),(1,3),(9,4),(2,1),(3,1),(4,1)],3).partitionBy(4,lambda x:x%2).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 4, 5]\n",
      "[[4], [5], [4], [5]]\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "allnumbers = sc.parallelize(xrange(2, n), 4).cache()\n",
    "def partitionsize(it): \n",
    "    s = 0\n",
    "    for i in it:\n",
    "        s += 1\n",
    "    yield s\n",
    "\n",
    "print allnumbers.mapPartitions(partitionsize).collect()\n",
    "print allnumbers.mapPartitions(partitionsize).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1915   54625</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83327   40420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1915   54625\n",
       "0  83327   40420"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./points.txt').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[797] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numPartitions = 10\n",
    "P = (5000, 5000)\n",
    "K = 10\n",
    "\n",
    "points = sc.textFile('points.txt',numPartitions)\n",
    "pairs = points.map(lambda l: tuple(l.split()))\n",
    "pairs = pairs.map(lambda pair: (int(pair[0]),int(pair[1])))\n",
    "pairs.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.broadcast.Broadcast at 0x10df87bd0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.broadcast(P)\n",
    "sub_top = K\n",
    "sc.broadcast(sub_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-219-7b7b57572056>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-219-7b7b57572056>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    top = [] # keep a top K list within each partition\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def close_f(iterator):\n",
    "    top = [] # keep a top K list within each partition\n",
    "    for x in iterator:\n",
    "        r2 = (P[0]-x[0])**2+(P[1]-x[1])**2 # distance^2\n",
    "        if len(top) < sub_top: # add to max length\n",
    "            top.append((r2,x))\n",
    "        else :\n",
    "            temp_value = [t[0] for t in top]\n",
    "            temp_max = max(temp_value) # longest distance\n",
    "            if temp_max > r2: #exchange if find a small one\n",
    "                for t in top:\n",
    "                    top.remove(t)\n",
    "                    break\n",
    "                top.append((r2,x))\n",
    "    yield top # a list of k near\n",
    "\n",
    "result = pairs.repartition(numPartitions).mapPartitions(close_f).flatMap(lambda x:x)\n",
    "\n",
    "result.sortByKey().take(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def close_f(iterator):\n",
    "    top = [] # keep a top K list within each partition\n",
    "    for x in iterator:\n",
    "        r2 = (P[0]-x[0])**2+(P[1]-x[1])**2 # distance^2\n",
    "        if len(top) < sub_top: # add to max length\n",
    "            top.append((r2,x))\n",
    "        else :\n",
    "            temp_value = [t[0] for t in top]\n",
    "            temp_max = max(temp_value) # longest distance\n",
    "            if temp_max > r2: #exchange if find a small one\n",
    "                for t in top:\n",
    "                    top.remove(t)\n",
    "                    break\n",
    "                top.append((r2,x))\n",
    "    yield top # a list of k near\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = pairs.repartition(numPartitions).mapPartitions(close_f).flatMap(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(724104, (5402, 4250)),\n",
       " (757325, (4587, 5766)),\n",
       " (2717585, (3601, 4128)),\n",
       " (3759850, (6935, 4875)),\n",
       " (5867413, (5537, 2638)),\n",
       " (6400584, (2522, 4490)),\n",
       " (7081785, (4496, 7613)),\n",
       " (8016178, (3797, 7563)),\n",
       " (9014437, (7511, 3354)),\n",
       " (10698820, (2448, 2954))]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sortByKey().take(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rule12 = g.find('(a)-[]->(b)').filter('a.id == \"h\"').select('b.name')\n",
    "rule34 = g.find('(a)-[g]->(c);(c)-[]->(b)').filter('a.id == \"h\"').filter('a.id != b.id').filter('g.relationship == \"friend\"').select('b.name')\n",
    "result = rule12.union(rule34).distinct()\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc, 10)\n",
    "\n",
    "numPartitions = 8\n",
    "rdd = sc.textFile('numbers.txt', numPartitions)\n",
    "rdd = rdd.map(lambda u: int(u))\n",
    "rddQueue = rdd.randomSplit([1]*100, 123)\n",
    "numbers = ssc.queueStream(rddQueue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3271.start.\n: java.lang.IllegalStateException: StreamingContext has already been stopped\n\tat org.apache.spark.streaming.StreamingContext.start(StreamingContext.scala:608)\n\tat org.apache.spark.streaming.api.java.JavaStreamingContext.start(JavaStreamingContext.scala:556)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-bd80c4407154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucas/anaconda/lib/python2.7/site-packages/pyspark/streaming/context.pyc\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mStart\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mStreamingContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activeContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucas/anaconda/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucas/anaconda/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucas/anaconda/lib/python2.7/site-packages/py4j/protocol.pyc\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3271.start.\n: java.lang.IllegalStateException: StreamingContext has already been stopped\n\tat org.apache.spark.streaming.StreamingContext.start(StreamingContext.scala:608)\n\tat org.apache.spark.streaming.api.java.JavaStreamingContext.start(JavaStreamingContext.scala:556)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "s = numbers.flatMap(lambda x:x).count()\n",
    "ssc.start()\n",
    "ssc.awaitTermination(200)\n",
    "ssc.stop(False)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
